# üõ°Ô∏è Bangla Cyberbullying Detection (Deep Learning Project)

This repository contains the development code for a **Bangla cyberbullying detection** system, created for the LSBU module **CSI_7_DEL ‚Äì Deep Learning**.

The goal is to classify Bangla social media comments into **five categories**:

- `Political`
- `Sexual`
- `Troll`
- `Threat`
- `Neutral`

The repo includes several models (baseline + deep learning) and a Streamlit app used for interactive inference and deployment.

---

## üìÇ Project Structure

```text
bangla_cyberbullying_dl/
‚îú‚îÄ‚îÄ app.py                      # Streamlit app (local / HF Spaces interface)
‚îú‚îÄ‚îÄ requirements.txt            # Python dependencies
‚îú‚îÄ‚îÄ readme.md                   # This file (development README)
‚îú‚îÄ‚îÄ LICENSE                     # Project license
‚îú‚îÄ‚îÄ data/                       # (Not tracked) raw / processed data
‚îÇ   ‚îî‚îÄ‚îÄ CyberBulling_Dataset_Bangla.xlsx   # Main labelled dataset (local only)
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îú‚îÄ‚îÄ banglabert_cyberbullying/         # Fine‚Äëtuned BanglaBERT model (HF format)
‚îÇ   ‚îú‚îÄ‚îÄ bilstm_bangla_cyberbullying.*     # Trained BiLSTM weights (.keras / .h5)
‚îÇ   ‚îú‚îÄ‚îÄ simple_nn_bangla_cyberbullying.*  # Trained simple NN model
‚îÇ   ‚îú‚îÄ‚îÄ bilstm_label_mapping.joblib       # Label ‚Üí index mapping for BiLSTM
‚îÇ   ‚îú‚îÄ‚îÄ simple_nn_label_mapping.joblib    # Label ‚Üí index mapping for simple NN
‚îÇ   ‚îî‚îÄ‚îÄ label_mapping.joblib              # Shared mapping (for legacy scripts)
‚îú‚îÄ‚îÄ notebooks/
‚îÇ   ‚îî‚îÄ‚îÄ eda.ipynb                # Exploratory data analysis notebook
‚îú‚îÄ‚îÄ results/
‚îÇ   ‚îú‚îÄ‚îÄ bilstm_results*.txt      # BiLSTM evaluation summaries
‚îÇ   ‚îú‚îÄ‚îÄ simple_nn_results*.txt   # Simple NN evaluation summaries
‚îÇ   ‚îú‚îÄ‚îÄ banglabert_results.txt   # BanglaBERT evaluation summary
‚îÇ   ‚îú‚îÄ‚îÄ bilstm_history.npy       # Keras training history (BiLSTM)
‚îÇ   ‚îú‚îÄ‚îÄ simple_nn_history.npy    # Keras training history (simple NN)
‚îÇ   ‚îî‚îÄ‚îÄ plots/                   # Generated plots (training curves, etc.)
‚îî‚îÄ‚îÄ src/
    ‚îú‚îÄ‚îÄ __init__.py
    ‚îú‚îÄ‚îÄ config.py                # Central config (paths, hyper‚Äëparameters)
    ‚îú‚îÄ‚îÄ data_utils.py            # Data loading, cleaning, splitting utilities
    ‚îú‚îÄ‚îÄ export_bilstm_to_h5.py   # Script to export BiLSTM to .h5 for deployment
    ‚îú‚îÄ‚îÄ inference.py             # `predict_label` + model loading helpers
    ‚îú‚îÄ‚îÄ plot_training_curves.py  # Plot loss/accuracy curves from history files
    ‚îú‚îÄ‚îÄ train_baseline_tfidf.py  # Baseline TF‚ÄëIDF + linear model
    ‚îú‚îÄ‚îÄ train_simple_nn.py       # Simple feed‚Äëforward neural network
    ‚îú‚îÄ‚îÄ train_bilstm.py          # BiLSTM model training
    ‚îî‚îÄ‚îÄ train_banglabert.py      # BanglaBERT / transformer fine‚Äëtuning
```

> Note: the **data** and **models** directories are intentionally not tracked by git (or are handled via Git LFS on the deployment repo) because of file size and privacy.

---

## üìä Dataset

The dataset consists of Bangla social media comments collected from platforms such as **YouTube, Facebook, and Twitter/X**. Each comment is annotated with one of the five cyberbullying categories listed above.

Typical dataset format (Excel):

- `Description` ‚Äì Bangla comment text
- `Label` ‚Äì one of `{political, sexual, troll, threat, neutral}`

The main dataset file is expected at:

```text
data/CyberBulling_Dataset_Bangla.xlsx
```

This file is **not** included in the repository and must be placed manually in the `data/` directory.

---

## üßπ Data Preparation

All data preparation logic is centralised in `src/data_utils.py` so that training scripts, notebooks, and the Streamlit app all share the same preprocessing steps.

Key steps:

1. **Column selection**  
   - Drop non‚Äësemantic index columns (e.g. `Unnamed: 0`).  
   - Keep `Description` (input text) and `Label` (target).

2. **Text cleaning** (applied to each comment):
   - Remove URLs (`http://`, `https://`, `www.`).
   - Remove user mentions (`@username`).
   - Normalise whitespace and strip leading/trailing spaces.
   - Optionally handle emojis / non‚ÄëBangla characters depending on the model.

3. **Filtering & deduplication**  
   - Drop rows with empty or missing text.  
   - Drop rows with missing labels.  
   - Remove exact duplicate rows.

4. **Label encoding**  
   - Create a mapping between text labels and integer indices, saved to `*.joblib` files for reuse at inference time.

5. **Train / validation / test split**  
   - Stratified split to preserve label proportions (e.g. 70/15/15).  
   - Optionally support custom splits via `config.py`.

6. **Input representations**  
   - For classical / deep models (simple NN, BiLSTM): tokenise and pad sequences.  
   - For transformers (BanglaBERT): use a Hugging Face tokenizer to create `input_ids` and `attention_mask` tensors.

---

## üß† Models

This repo includes several modelling approaches used in the coursework experiments:

1. **Baseline ‚Äì TF‚ÄëIDF + Linear Classifier**  
   Implemented in `src/train_baseline_tfidf.py` using scikit‚Äëlearn. Serves as a classical ML baseline.

2. **Simple Neural Network (MLP)**  
   Implemented in `src/train_simple_nn.py`. Uses an embedding + averaged representation (or TF‚ÄëIDF) followed by dense layers for 5‚Äëway classification.

3. **BiLSTM (Main Deployed DL Model)**  
   Implemented in `src/train_bilstm.py`. Architecture typically includes:
   - Embedding layer (random or pre‚Äëtrained)  
   - Bidirectional LSTM layer(s)  
   - Dense layers with dropout  
   - Softmax output over the 5 classes

   Trained weights are saved under `models/bilstm_bangla_cyberbullying.*` and are loaded by the Streamlit app through `src.inference.py`.

4. **BanglaBERT / Transformer (Advanced Model)**  
   Implemented in `src/train_banglabert.py` using Hugging Face `transformers`.  
   This model is more computationally expensive and mainly used for comparison and analysis. The fine‚Äëtuned model is stored in `models/banglabert_cyberbullying/`.

---

## üìà Evaluation & Results

Evaluation artefacts are saved in the `results/` folder:

- `*_results.txt` ‚Äì summary metrics (accuracy, precision, recall, F1, etc.).
- `*_history.npy` ‚Äì Keras training history objects (loss/accuracy per epoch).
- `results/plots/` ‚Äì figures produced by `src/plot_training_curves.py`.

These files were used to compare models in the written report and to justify the choice of BiLSTM as the main deployed model.

---

## üöÄ Training the Models

Before training, ensure the virtual environment is active and the dataset is in `data/`.

### 1. Baseline (TF‚ÄëIDF)

```bash
python -m src.train_baseline_tfidf
```

### 2. Simple Neural Network

```bash
python -m src.train_simple_nn
```

### 3. BiLSTM

```bash
python -m src.train_bilstm
```

### 4. BanglaBERT (Optional, GPU recommended)

```bash
python -m src.train_banglabert
```

Training scripts will automatically write results to the `results/` directory and save models under `models/` (paths and hyper‚Äëparameters are controlled from `src/config.py`).

---

## üåê Streamlit App (Local / Hugging Face)

The interactive interface is implemented in `app.py` and uses the **BiLSTM** model via the helper functions in `src/inference.py`.

### Run locally

```bash
streamlit run app.py
```

The app supports:

- Free‚Äëtext input for a single Bangla comment.
- A small list of built‚Äëin demo examples (one per class).
- Display of predicted label and class probabilities.

### Deploy to Hugging Face Spaces

The same `app.py` can be used as the entry point for a Hugging Face Space:

1. Create a new Space (SDK = Streamlit).
2. Push this repo (or a deployment‚Äëonly copy) to the Space.
3. Upload the trained BiLSTM model files to the `models/` folder in the Space.
4. Ensure `requirements.txt` matches the versions used during development.

The Space will automatically start the Streamlit app using `app.py`.

---

## üîß Installation (Development Environment)

1. **Clone the repository**

```bash
git clone https://github.com/<your-username>/bangla_cyberbullying_dl.git
cd bangla_cyberbullying_dl
```

2. **Create and activate a virtual environment**

```bash
python3 -m venv .venv
source .venv/bin/activate      # macOS / Linux
# .venv\Scripts\activate      # Windows
```

3. **Install dependencies**

```bash
pip install --upgrade pip
pip install -r requirements.txt
```

4. **Add local data and models**

- Place the Excel dataset in `data/`.  
- Place trained model files (if already trained) in `models/`.  
- Alternatively, run the training scripts to regenerate models.

---

## üßæ Coursework Mapping (CSI_7_DEL)

This development repo underpins the written deep learning coursework:

- **Data Understanding & Preparation** ‚Äì implemented mainly in `src/data_utils.py` and `notebooks/eda.ipynb`.
- **Modelling & Evaluation** ‚Äì implemented in the various `train_*.py` scripts and stored in `results/`.
- **Deployment** ‚Äì implemented through `app.py` (local Streamlit + Hugging Face Space).

The README is focused on the **developer view** of the project so the codebase can be understood and reused later.

---

## ¬© Copyright

¬© 2025 Benjamin Mehrdad. All rights reserved.
